{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEM length & diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/2020_S/destructive/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.xlsx')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['0324', '0421', '0522', '0617', '0707', '0708', '0709']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df = {}\n",
    "node_dia_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[-1:]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=1)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        temp_len = np.append(temp_df[key]['stem length(cm)'].dropna().values, temp_df[key]['stem length(cm).1'].dropna().values).astype('float')\n",
    "        temp_dia = np.append(temp_df[key]['stem diameter(mm)'].dropna().values, temp_df[key]['stem diameter(mm).1'].dropna().values).astype('float')\n",
    "        node_len_df[key] = temp_len.mean()\n",
    "        node_dia_df[key] = temp_dia[temp_dia >= 5].mean()\n",
    "\n",
    "    _ += 1 \n",
    "node_len_df = pd.DataFrame(node_len_df, index=['node_length']).T\n",
    "node_dia_df = pd.DataFrame(node_dia_df, index=['node_diameter']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len = []\n",
    "node_dia = []\n",
    "for _ in range(4):\n",
    "    node_len.append(node_len_df.filter(like=dates[_], axis=0).values.T.squeeze())\n",
    "    node_dia.append(node_dia_df.filter(like=dates[_], axis=0).values.T.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df = {}\n",
    "node_dia_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[:-1]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=1)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "        try:\n",
    "            temp_len = np.append(temp_df[key]['internode length'].dropna().values, temp_df[key]['internode length.1'].dropna().values).astype('float')\n",
    "            temp_dia = np.append(temp_df[key]['internode diameter'].dropna().values, temp_df[key]['Unnamed: 12'].dropna().values).astype('float')\n",
    "            node_len_df[key + '_' + dates[-3:][_]] = temp_len.mean()\n",
    "            node_dia_df[key + '_' + dates[-3:][_]] = temp_dia[temp_dia >= 5].mean()\n",
    "        except KeyError:\n",
    "            temp_len = np.append(temp_df[key]['internode length'].dropna().values, temp_df[key]['Unnamed: 10'].dropna().values).astype('float')\n",
    "            temp_dia = np.append(temp_df[key]['internode diameter'].dropna().values, temp_df[key]['Unnamed: 12'].dropna().values).astype('float')\n",
    "            node_len_df[key + '_' + dates[-3:][_]] = temp_len.mean()\n",
    "            node_dia_df[key + '_' + dates[-3:][_]] = temp_dia[temp_dia >= 5].mean()\n",
    "            \n",
    "    _ += 1 \n",
    "node_len_df = pd.DataFrame(node_len_df, index=['node_length']).T\n",
    "node_dia_df = pd.DataFrame(node_dia_df, index=['node_diameter']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_len_df = node_len_df.filter(like='A2', axis=0)\n",
    "a2_dia_df = node_dia_df.filter(like='A2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    node_len.append(a2_len_df.filter(like=dates[-3:][_], axis=0).values.T.squeeze())\n",
    "    node_dia.append(a2_dia_df.filter(like=dates[-3:][_], axis=0).values.T.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df = pd.DataFrame(node_len, index=['2020-03-24', '2020-04-21', '2020-05-22', '2020-06-17', '2020-07-07', '2020-07-08', '2020-07-09'])\n",
    "node_dia_df = pd.DataFrame(node_dia, index=['2020-03-24', '2020-04-21', '2020-05-22', '2020-06-17', '2020-07-07', '2020-07-08', '2020-07-09'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df.index = pd.DatetimeIndex(node_len_df.index)\n",
    "node_dia_df.index = pd.DatetimeIndex(node_dia_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df.to_csv('./results/2020_S/node_length.csv')\n",
    "node_dia_df.to_csv('./results/2020_S/node_diameter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/2020_W/destructive/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.xlsx')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2020-09-09', '2020-10-14', '2020-11-13', '2020-12-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df = {}\n",
    "node_dia_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[:-1]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=1)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        temp_len = np.append(temp_df[key]['internode length'].dropna().values, temp_df[key]['internode length.1'].dropna().values).astype('float')\n",
    "        temp_dia = np.append(temp_df[key]['internode diameter'].dropna().values, temp_df[key]['internode diameter.1'].dropna().values).astype('float')\n",
    "        node_len_df[dates[_] + '_' + key] = temp_len.mean()\n",
    "        node_dia_df[dates[_] + '_' + key] = temp_dia[temp_dia >= 5].mean()\n",
    "    _ += 1 \n",
    "node_len_df = pd.DataFrame(node_len_df, index=['node_length']).T\n",
    "node_dia_df = pd.DataFrame(node_dia_df, index=['node_diameter']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df = node_len_df.drop(node_len_df.filter(like='RB', axis=0).index)\n",
    "node_dia_df = node_dia_df.drop(node_dia_df.filter(like='RB', axis=0).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len = []\n",
    "node_dia = []\n",
    "for _ in range(4):\n",
    "    node_len.append(node_len_df.filter(like=dates[_], axis=0).values.T.squeeze())\n",
    "    node_dia.append(node_dia_df.filter(like=dates[_], axis=0).values.T.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df = {}\n",
    "node_dia_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[-1:]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=0)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        temp_len = np.append(temp_df[key]['Main stem'].dropna().iloc[1:].values, temp_df[key]['Side stem'].dropna().iloc[1:].values).astype('float')\n",
    "        temp_dia = np.append(temp_df[key]['Main stem.1'].dropna().iloc[1:].values, temp_df[key]['Side stem '].dropna().iloc[1:].values).astype('float')\n",
    "        node_len_df[key] = temp_len.mean()\n",
    "        node_dia_df[key] = temp_dia[temp_dia >= 5].mean()\n",
    "            \n",
    "    _ += 1 \n",
    "node_len_df = pd.DataFrame(node_len_df, index=['node_length']).T\n",
    "node_dia_df = pd.DataFrame(node_dia_df, index=['node_diameter']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_len_df = node_len_df.filter(like='a2', axis=0)\n",
    "a2_dia_df = node_dia_df.filter(like='a2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len.append(a2_len_df.values.T.squeeze())\n",
    "node_dia.append(a2_dia_df.values.T.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df = pd.DataFrame(node_len, index=['2020-09-09', '2020-10-14', '2020-11-13', '2020-12-11', '2021-01-25'])\n",
    "node_dia_df = pd.DataFrame(node_dia, index=['2020-09-09', '2020-10-14', '2020-11-13', '2020-12-11', '2021-01-25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df.index = pd.DatetimeIndex(node_len_df.index)\n",
    "node_dia_df.index = pd.DatetimeIndex(node_dia_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df.loc['2021-01-25'] /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_len_df.to_csv('./results/2020_W/node_length.csv')\n",
    "node_dia_df.to_csv('./results/2020_W/node_diameter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/2020_S/destructive/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.xlsx')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['0324', '0421', '0522', '0617', '0707', '0708', '0709']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_area_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[-1:]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=0)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        leaf_area_df[key] = [temp_df[key]['leaf area'][0]]\n",
    "    _ += 1 \n",
    "leaf_area_df = pd.DataFrame.from_dict(leaf_area_df).T\n",
    "leaf_area_df.columns = ['leaf area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_areas = []\n",
    "for _ in range(4):\n",
    "    leaf_areas.append(leaf_area_df.filter(like=dates[_], axis=0).values.T.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_area_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[:-1]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=0)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        leaf_area_df[key + '_' + dates[-3:][_]] = [temp_df[key]['leaf area'][0]]\n",
    "    _ += 1 \n",
    "leaf_area_df = pd.DataFrame.from_dict(leaf_area_df).T\n",
    "leaf_area_df.columns = ['leaf area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_df = leaf_area_df.filter(like='A2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    leaf_areas.append(a2_df.filter(like=dates[-3:][_], axis=0).values.T.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_area_df = pd.DataFrame(leaf_areas, index=['2020-03-24', '2020-04-21', '2020-05-22', '2020-06-17', '2020-07-07', '2020-07-08', '2020-07-09'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_area_df.index = pd.DatetimeIndex(leaf_area_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_area_df.to_csv('./results/2020_S/leaf_area.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/2020_W/destructive/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.xlsx')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2020-09-09', '2020-10-14', '2020-11-13', '2020-12-11', '2021-01-25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_area_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=0)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        leaf_area_df[dates[_] + '_' + key] = [temp_df[key].loc[:2, 'leaf area'].sum()]\n",
    "    _ += 1 \n",
    "leaf_area_df = pd.DataFrame.from_dict(leaf_area_df).T\n",
    "leaf_area_df.columns = ['leaf_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_area_df = leaf_area_df.drop(leaf_area_df.filter(like='RB', axis=0).index)\n",
    "leaf_area_df = leaf_area_df.drop(leaf_area_df.filter(like='a3', axis=0).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_area_df.index = ['2020-09-09']*3 + ['2020-10-14']*6 + ['2020-11-13']*6 + ['2020-12-11']*3 + ['2021-01-25']*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_area_df.index = pd.DatetimeIndex(leaf_area_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_area_df.to_csv('./results/2020_W/leaf_area.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant heights & num nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/2020_S/destructive/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.xlsx')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['0324', '0421', '0522', '0617', '0707', '0708', '0709']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df = {}\n",
    "num_nodes_df = {}\n",
    "for FILENAME in dataset_list[-1:]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=1)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "        temp_target = temp_df[key].loc[:, 'stem length(cm)':'stem diameter(mm).1'].dropna(axis=0, how='all')\n",
    "        temp_target.loc[:, 'stem length(cm).1'] = temp_target['stem length(cm).1'].combine_first(temp_target['stem length(cm)'])\n",
    "        temp_target.loc[:, 'stem diameter(mm).1'] = temp_target['stem diameter(mm).1'].combine_first(temp_target['stem diameter(mm)'])\n",
    "        \n",
    "        plant_height_df[key] = max(temp_target.iloc[:, :2].sum())\n",
    "        num_nodes_df[key] = temp_target.shape[0]\n",
    "plant_height_df = pd.DataFrame.from_dict([plant_height_df]).T\n",
    "plant_height_df.columns = ['plant_height']\n",
    "num_nodes_df = pd.DataFrame.from_dict([num_nodes_df]).T\n",
    "num_nodes_df.columns = ['num_nodes_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height = []\n",
    "for _ in range(4):\n",
    "    plant_height.append(plant_height_df.filter(like=dates[_], axis=0).values.T.squeeze())\n",
    "num_nodes = []\n",
    "for _ in range(4):\n",
    "    num_nodes.append(num_nodes_df.filter(like=dates[_], axis=0).values.T.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df = {}\n",
    "num_nodes_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[:-1]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=1)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "        temp_target = temp_df[key].loc[:, 'internode length':'Unnamed: 12'].dropna(axis=0, how='all')\n",
    "        try:\n",
    "            temp_target.loc[:, 'internode length.1'] = temp_target['internode length.1'].combine_first(temp_target['internode length'])\n",
    "        except KeyError:\n",
    "            temp_target.loc[:, 'Unnamed: 10'] = temp_target['Unnamed: 10'].combine_first(temp_target['internode length'])\n",
    "        temp_target.loc[:, 'Unnamed: 12'] = temp_target['Unnamed: 12'].combine_first(temp_target['internode diameter'])\n",
    "        \n",
    "        plant_height_df[key + '_' + dates[-3:][_]] = max(temp_target.iloc[:, :2].sum())\n",
    "        num_nodes_df[key + '_' + dates[-3:][_]] = temp_target.shape[0]\n",
    "    _ += 1\n",
    "plant_height_df = pd.DataFrame.from_dict([plant_height_df]).T\n",
    "plant_height_df.columns = ['plant_height']\n",
    "num_nodes_df = pd.DataFrame.from_dict([num_nodes_df]).T\n",
    "num_nodes_df.columns = ['num_nodes_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_df = plant_height_df.filter(like='A2', axis=0)\n",
    "a2_df_ = num_nodes_df.filter(like='A2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    plant_height.append(a2_df.filter(like=dates[-3:][_], axis=0).values.T.squeeze())\n",
    "    num_nodes.append(a2_df_.filter(like=dates[-3:][_], axis=0).values.T.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df = pd.DataFrame(plant_height, index=['2020-03-24', '2020-04-21', '2020-05-22', '2020-06-17', '2020-07-07', '2020-07-08', '2020-07-09'])\n",
    "num_nodes_df = pd.DataFrame(num_nodes, index=['2020-03-24', '2020-04-21', '2020-05-22', '2020-06-17', '2020-07-07', '2020-07-08', '2020-07-09'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df.index = pd.DatetimeIndex(plant_height_df.index)\n",
    "num_nodes_df.index = pd.DatetimeIndex(num_nodes_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df.to_csv('./results/2020_S/plant_height.csv')\n",
    "num_nodes_df.to_csv('./results/2020_S/num_nodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/2020_W/destructive/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.xlsx')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2020-09-09', '2020-10-14', '2020-11-13', '2020-12-11', '2021-01-25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plant_height_df = {}\n",
    "# num_nodes_df = {}\n",
    "# for FILENAME in dataset_list:\n",
    "#     temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=0)\n",
    "#     for key in temp_df.keys():\n",
    "#         if temp_df[key].shape[0] == 0:\n",
    "#             continue\n",
    "        \n",
    "#         plant_height_df[key] = temp_df[key].loc[0, 'Plant height']\n",
    "# _ = pd.DataFrame.from_dict([plant_height_df])\n",
    "# _.columns = plant_height_df.keys()\n",
    "# plant_height_df = _.T\n",
    "# plant_height_df.columns = ['plant_height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df = {}\n",
    "num_nodes_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=1)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "        try:\n",
    "            temp_target = temp_df[key].loc[:, 'internode length':'internode diameter.1'].dropna(axis=0, how='all')\n",
    "            temp_target.loc[:, 'internode length.1'] = temp_target['internode length.1'].combine_first(temp_target['internode length'])\n",
    "            temp_target.loc[:, 'internode diameter.1'] = temp_target['internode diameter.1'].combine_first(temp_target['internode diameter'])\n",
    "        except KeyError:\n",
    "            temp_target = temp_df[key].loc[:, 'stem length(mm)':'stem diameter(mm).1'].dropna(axis=0, how='all')\n",
    "            temp_target.loc[:, 'stem length(cm)'] = temp_target['stem length(cm)'].combine_first(temp_target['stem length(mm)'])\n",
    "            temp_target.loc[:, 'stem diameter(mm).1'] = temp_target['stem diameter(mm).1'].combine_first(temp_target['stem diameter(mm)'])\n",
    "        \n",
    "        plant_height_df[dates[_] + '_' + key] = max(temp_target.iloc[:, :2].sum())\n",
    "        num_nodes_df[dates[_] + '_' + key] = temp_target.shape[0]\n",
    "    _ += 1\n",
    "plant_height_df = pd.DataFrame.from_dict([plant_height_df]).T\n",
    "plant_height_df.columns = ['plant_height']\n",
    "num_nodes_df = pd.DataFrame.from_dict([num_nodes_df]).T\n",
    "num_nodes_df.columns = ['num_nodes_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df = plant_height_df.drop(plant_height_df.filter(like='RB', axis=0).index)\n",
    "plant_height_df = plant_height_df.drop(plant_height_df.filter(like='a3', axis=0).index)\n",
    "num_nodes_df = num_nodes_df.drop(num_nodes_df.filter(like='RB', axis=0).index)\n",
    "num_nodes_df = num_nodes_df.drop(num_nodes_df.filter(like='a3', axis=0).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df.index = ['2020-09-09']*3 + ['2020-10-14']*6 + ['2020-11-13']*6 + ['2020-12-11']*3 + ['2021-01-25']*15\n",
    "num_nodes_df.index = ['2020-09-09']*3 + ['2020-10-14']*6 + ['2020-11-13']*6 + ['2020-12-11']*3 + ['2021-01-25']*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height = []\n",
    "num_nodes = []\n",
    "for _ in range(5):\n",
    "    plant_height.append(plant_height_df.filter(like=plant_height_df.index.unique()[_], axis=0).values.T.squeeze())\n",
    "    num_nodes.append(num_nodes_df.filter(like=num_nodes_df.index.unique()[_], axis=0).values.T.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df = pd.DataFrame(plant_height, index=['2020-09-09', '2020-10-14', '2020-11-13', '2020-12-11', '2021-01-25'])\n",
    "num_nodes_df = pd.DataFrame(num_nodes, index=['2020-09-09', '2020-10-14', '2020-11-13', '2020-12-11', '2021-01-25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df.index = pd.DatetimeIndex(plant_height_df.index)\n",
    "num_nodes_df.index = pd.DatetimeIndex(num_nodes_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df.loc['2021-01-25'] /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_height_df.to_csv('./results/2020_W/plant_height.csv')\n",
    "num_nodes_df.to_csv('./results/2020_W/num_nodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/2020_S/destructive/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.xlsx')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['destructive(0707)_.xlsx',\n",
       " 'destructive(0708).xlsx',\n",
       " 'destructive(0709).xlsx',\n",
       " 'destructive_CT_(0324-0421-0519-0617).xlsx']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[-1:]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=0)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        FW_df[key] = temp_df[key][['Stem FW', 'Leaf FW', 'petiole FW', 'Fruit count', 'Idv fruit FW', 'Plant height']].iloc[:10, :].sum()\n",
    "    _ += 1 \n",
    "FW_df = pd.DataFrame.from_dict(FW_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df.index = ['2020-03-24']*3 + ['2020-04-21']*3 + ['2020-05-22']*3 + ['2020-06-17']*4\n",
    "__ = FW_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[:-1]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=0)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        FW_df[key] = temp_df[key][['Stem FW', 'Leaf FW', 'petiole FW', 'Fruit count', 'Idv fruit FW', 'Plant height']].iloc[:10, :].sum()\n",
    "    _ += 1 \n",
    "FW_df = pd.DataFrame.from_dict(FW_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df = FW_df.filter(like='A2', axis=0)\n",
    "FW_df.index = ['2020-07-07' for i in range(len(FW_df.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df = pd.concat([__, FW_df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dry weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[-1:]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=22)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        DW_df[key] = temp_df[key][['Stem DW', 'Leaf DW', 'petiole DW', 'Fruit DW']].iloc[:3, :].sum()\n",
    "    _ += 1 \n",
    "DW_df = pd.DataFrame.from_dict(DW_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df.index = ['2020-03-24']*3 + ['2020-04-21']*3 + ['2020-05-22']*3 + ['2020-06-17']*4\n",
    "__ = DW_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[:-1]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=22)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        DW_df[key] = temp_df[key][['Stem DW', 'Leaf DW', 'petiole DW', 'Fruit DW']].iloc[:3, :].sum()\n",
    "    _ += 1 \n",
    "DW_df = pd.DataFrame.from_dict(DW_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df = DW_df.filter(like='A2', axis=0)\n",
    "DW_df.index = ['2020-07-07' for i in range(len(DW_df.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df = pd.concat([__, DW_df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df = pd.concat([FW_df, DW_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df.to_csv('./results/2020_S/weight_ct.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Winter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/2020_W/destructive/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.xlsx')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['destructive_investigation_200909_wDW.xlsx',\n",
       " 'destructive_investigation_201014_wDW.xlsx',\n",
       " 'destructive_investigation_201113_wDW.xlsx',\n",
       " 'destructive_investigation_201211_wDW.xlsx',\n",
       " 'destructive_investigation_210125_wDW.xlsx']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FW_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list:\n",
    "    tag = FILENAME.split('_')[-2]\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=0)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        FW_df[tag + '_' + key] = temp_df[key][['Stem FW', 'Leaf FW', 'petiole FW', 'Fruit count', 'Idv fruit FW', 'Plant height']].iloc[:10, :].sum()\n",
    "    _ += 1 \n",
    "FW_df = pd.DataFrame.from_dict(FW_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df = FW_df.loc[[_ for _ in FW_df.index if not 'a3' in _], :]\n",
    "FW_df = FW_df.drop([_ for _ in FW_df.index if 'RB' in _])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df.index = ['2020-09-09']*3 + ['2020-10-14']*6 + ['2020-11-13']*6 + ['2020-12-11']*3 + ['2021-01-25']*15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dry weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=22)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        DW_df[key] = temp_df[key][['Stem DW', 'Leaf DW', 'petiole DW', 'Fruit DW']].iloc[:3, :].sum()\n",
    "    _ += 1 \n",
    "DW_df = pd.DataFrame.from_dict(DW_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df = DW_df.loc[[_ for _ in DW_df.index if not 'a3' in _], :]\n",
    "DW_df = DW_df.drop([_ for _ in DW_df.index if 'RB' in _])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df.index = ['2020-09-09']*3 + ['2020-10-14']*6 + ['2020-11-13']*6 + ['2020-12-11']*3 + ['2021-01-25']*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df = pd.concat([FW_df, DW_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df.to_csv('./results/2020_W/weight_ct.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Far-red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/2020_S/destructive/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.xlsx')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[:-1]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=0)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        FW_df[key] = temp_df[key][['Stem FW', 'Leaf FW', 'petiole FW', 'Fruit count', 'Idv fruit FW', 'Plant height']].iloc[:10, :].sum()\n",
    "    _ += 1 \n",
    "FW_df = pd.DataFrame.from_dict(FW_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df = FW_df.filter(like='A3', axis=0)\n",
    "FW_df.index = ['2020-07-07' for i in range(len(FW_df.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dry weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list[:-1]:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=22)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        DW_df[key] = temp_df[key][['Stem DW', 'Leaf DW', 'petiole DW', 'Fruit DW']].iloc[:3, :].sum()\n",
    "    _ += 1 \n",
    "DW_df = pd.DataFrame.from_dict(DW_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df = DW_df.filter(like='A3', axis=0)\n",
    "DW_df.index = ['2020-07-07' for i in range(len(DW_df.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df = pd.concat([FW_df, DW_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df.to_csv('./results/2020_S/weight_fr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interlighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Winter Fresh weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './data/2020_W/destructive/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.xlsx')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=0)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        FW_df[key] = temp_df[key][['Stem FW', 'Leaf FW', 'petiole FW', 'Fruit count', 'Idv fruit FW', 'Plant height']].iloc[:10, :].sum()\n",
    "    _ += 1 \n",
    "FW_df = pd.DataFrame.from_dict(FW_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW_df.index = ['2020-09-09']*3 + ['2020-10-14']*6 + ['2020-11-13']*6 + ['2020-12-11_']*3 + ['2020-12-11']*3\n",
    "__ = FW_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__rb = __.loc['2020-12-11_']\n",
    "__rb.index = ['2020-12-11']*3\n",
    "__ = __.drop('2020-12-11_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dry weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df = {}\n",
    "_ = 0\n",
    "for FILENAME in dataset_list:\n",
    "    temp_df = pd.read_excel(DIRECTORY + FILENAME, sheet_name=None, skiprows=22)\n",
    "    for key in temp_df.keys():\n",
    "        if temp_df[key].shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        DW_df[key] = temp_df[key][['Stem DW', 'Leaf DW', 'petiole DW', 'Fruit DW']].iloc[:3, :].sum()\n",
    "    _ += 1 \n",
    "DW_df = pd.DataFrame.from_dict(DW_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_df.index = ['2020-09-09']*3 + ['2020-10-14']*6 + ['2020-11-13']*6 + ['2020-12-11_']*3 + ['2020-12-11']*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_rb_df = DW_df.loc['2020-12-11_']\n",
    "DW_rb_df.index = ['2020-12-11']*3\n",
    "DW_df = DW_df.drop('2020-12-11_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_ct_df = pd.concat([__, DW_df], axis=1, sort=False)\n",
    "weight_rb_df = pd.concat([__rb, DW_rb_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_ct_df.to_csv('./results/2020_W/ct_weight.csv')\n",
    "weight_rb_df.to_csv('./results/2020_W/rb_weight.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
