{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "import tensorflow_addons as tfa\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import (LinearLocator, MultipleLocator, FormatStrFormatter)\n",
    "from matplotlib.dates import MONDAY\n",
    "from matplotlib.dates import MonthLocator, WeekdayLocator, DateFormatter\n",
    "from matplotlib import gridspec\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = ((8/2.54), (6/2.54))\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"mathtext.default\"] = \"rm\"\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "MARKER_SIZE = 15\n",
    "cmap_m = [\"#f4a6ad\", \"#f6957e\", \"#fccfa2\", \"#8de7be\", \"#86d6f2\", \"#24a9e4\", \"#b586e0\", \"#d7f293\"]\n",
    "cmap = [\"#e94d5b\", \"#ef4d28\", \"#f9a54f\", \"#25b575\", \"#1bb1e7\", \"#1477a2\", \"#a662e5\", \"#c2f442\"]\n",
    "\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "# plt.rcParams['axes.edgecolor'] = \n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.width'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED = './models/ffnn.h5'\n",
    "BEST_PATH = './models/ffnn_transfer.h5'\n",
    "TRAINING_EPOCHS = 200\n",
    "LEARNING_RATE = 0.0001\n",
    "EPSILON = 1e-08\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.load('./results/2020_W/fw_ct_dataset.npz', allow_pickle=True)\n",
    "data_indices = l['data_indices']\n",
    "input_data = l['input_data']\n",
    "output_label = l['output_label']\n",
    "INPUT_MAXS = l['INPUT_MAXS']\n",
    "INPUT_MINS = l['INPUT_MINS']\n",
    "OUTPUT_MAX = l['OUTPUT_MAX']\n",
    "OUTPUT_MIN = l['OUTPUT_MIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_data.astype('float32')\n",
    "output_label = output_label.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_data.reshape(input_data.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456, 1296)\n",
      "(456, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input_data.shape)\n",
    "print(output_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  42.31875   99.      1313.3       78.755     10.006      5.057\n",
      "   36.58      55.877     19.731  ]\n",
      "[11.5     4.4325 -0.5957 32.115   0.205   0.112  11.53    8.744  11.393 ]\n"
     ]
    }
   ],
   "source": [
    "print(INPUT_MAXS)\n",
    "print(INPUT_MINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5180414673761202\n",
      "0.31621880464190666\n"
     ]
    }
   ],
   "source": [
    "print(OUTPUT_MAX)\n",
    "print(OUTPUT_MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_indices, input_data, output_label = shuffle(data_indices, input_data, output_label, random_state=3101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = int(input_data.shape[0]*.09)\n",
    "N_DEV = int(input_data.shape[0]/3)\n",
    "TRAIN_INDEX = [_ for _ in range(N_TRAIN)] + \\\n",
    "              [_ for _ in range(N_DEV, N_DEV+N_TRAIN)] + \\\n",
    "              [_ for _ in range(N_DEV*2, N_DEV*2+N_TRAIN)]\n",
    "VAL_INDEX = [_ for _ in range(input_data.shape[0]) if _ not in TRAIN_INDEX]\n",
    "train_input = input_data[TRAIN_INDEX, ...]\n",
    "train_label = output_label[TRAIN_INDEX, ...]\n",
    "train_indices = data_indices[TRAIN_INDEX]\n",
    "val_input = input_data[VAL_INDEX, ...]\n",
    "val_label = output_label[VAL_INDEX, ...]\n",
    "val_indices = data_indices[VAL_INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data set: 456\n",
      "number of training set: 123\n",
      "number of validation set: 333\n"
     ]
    }
   ],
   "source": [
    "print(f'number of data set: {input_data.shape[0]}')\n",
    "print(f'number of training set: {train_input.shape[0]}')\n",
    "print(f'number of validation set: {val_input.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_input, train_label))\n",
    "    train_dataset = train_dataset.cache().shuffle(BATCH_SIZE*10).batch(BATCH_SIZE, drop_remainder=False)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_input, val_label))\n",
    "    val_dataset = val_dataset.cache().shuffle(BATCH_SIZE*10).batch(BATCH_SIZE, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(512, activation=tf.nn.sigmoid),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, activation=tf.nn.sigmoid),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(32),\n",
    "        layers.Dense(1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=.5, patience=2, verbose=0, mode='min',\n",
    "    min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "save = callbacks.ModelCheckpoint(\n",
    "    BEST_PATH, monitor='val_loss', verbose=0,\n",
    "    save_best_only=True, save_weights_only=True, mode='min', save_freq='epoch')\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    opt = optimizers.Adam(learning_rate=LEARNING_RATE, epsilon=EPSILON)\n",
    "    model.compile(optimizer=opt, loss='mae')\n",
    "    model.predict(val_dataset)\n",
    "    model.load_weights(PRE_TRAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Sequential(model.layers[:-2])\n",
    "prediction_layer1 = layers.Dense(32)\n",
    "prediction_layer2 = layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential([\n",
    "    base_model,\n",
    "    prediction_layer1,\n",
    "    prediction_layer2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    opt = optimizers.Adam(learning_rate=LEARNING_RATE, epsilon=EPSILON)\n",
    "    new_model.compile(optimizer=opt, loss='mae')\n",
    "    new_model.fit(train_dataset, epochs=TRAINING_EPOCHS, validation_data=val_dataset,\n",
    "                  verbose=1, callbacks=[cbs, save, early_stop]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.load_weights(BEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output = new_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output = pred_output*(OUTPUT_MAX - OUTPUT_MIN) + OUTPUT_MIN\n",
    "val_label = val_label*(OUTPUT_MAX - OUTPUT_MIN) + OUTPUT_MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=((8.5/2.54*2), (6/2.54*2)))\n",
    "ax0 = plt.subplot()\n",
    "\n",
    "ax0.spines['right'].set_visible(False)\n",
    "ax0.spines['left'].set_position(('outward', 5))\n",
    "ax0.spines['bottom'].set_position(('outward', 5))\n",
    "\n",
    "ax0.plot(val_label, pred_output, 'o', ms=5, mec='k', c=cmap[0])\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(val_label, index=val_indices[:, 0], columns=['label'])\n",
    "pred_df['pred'] = pred_output\n",
    "pred_df.index = pd.DatetimeIndex(pred_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=((8.5/2.54*2), (6/2.54*2)))\n",
    "ax0 = plt.subplot()\n",
    "\n",
    "ax0.spines['right'].set_visible(False)\n",
    "ax0.spines['left'].set_position(('outward', 5))\n",
    "ax0.spines['bottom'].set_position(('outward', 5))\n",
    "\n",
    "ax0.plot(pred_df.index, pred_df['label'], '-o', ms=5, mec='k', c=cmap[4])\n",
    "ax0.plot(pred_df.index, pred_df['pred'], 'o', ms=5, mec='k', c=cmap[0])\n",
    "\n",
    "ax0.set_ybound(0, 2)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('./results/model_output/ffnn_tf.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
