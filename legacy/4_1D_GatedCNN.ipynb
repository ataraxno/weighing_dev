{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PATH = './models/ResNet_1D.h5'\n",
    "TRAINING_EPOCHS = 200\n",
    "LEARNING_RATE = 0.02\n",
    "EPSILON = 1e-06\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.load('./results/2020_S/fw_dataset.npz', allow_pickle=True)\n",
    "data_indices = l['data_indices']\n",
    "input_data = l['input_data']\n",
    "output_label = l['output_label']\n",
    "INPUT_MAXS = l['INPUT_MAXS']\n",
    "INPUT_MINS = l['INPUT_MINS']\n",
    "OUTPUT_MAX = l['OUTPUT_MAX']\n",
    "OUTPUT_MIN = l['OUTPUT_MIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_data.astype('float32')\n",
    "output_label = output_label.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_data.shape)\n",
    "print(output_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(INPUT_MAXS)\n",
    "print(INPUT_MINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OUTPUT_MAX)\n",
    "print(OUTPUT_MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indices, input_data, output_label = shuffle(data_indices, input_data, output_label, random_state=3101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = int(input_data.shape[0]*.8)\n",
    "train_input = input_data[:N_TRAIN, ...]\n",
    "train_label = output_label[:N_TRAIN, ...]\n",
    "val_input = input_data[N_TRAIN:, ...]\n",
    "val_label = output_label[N_TRAIN:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of training set: {train_input.shape[0]}')\n",
    "print(f'number of validation set: {val_input.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_input, train_label))\n",
    "    train_dataset = train_dataset.cache().shuffle(BATCH_SIZE*10).batch(BATCH_SIZE, drop_remainder=True)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_input, val_label))\n",
    "    val_dataset = val_dataset.cache().shuffle(BATCH_SIZE*10).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.f = filters\n",
    "        self.k = kernel_size\n",
    "        \n",
    "        self.downsampling = layers.Conv1D(self.f, 1, kernel_initializer='glorot_normal', padding='same')\n",
    "        self.downbatch = layers.BatchNormalization()\n",
    "    \n",
    "        self.conv1 = layers.Conv1D(self.f/4, 1, kernel_initializer='glorot_normal', padding='same')\n",
    "        self.batch1 = layers.BatchNormalization()\n",
    "        self.activation1 = layers.Activation(tf.nn.relu)\n",
    "        \n",
    "        self.conv2_1 = layers.Conv1D(self.f/4, self.k[0], kernel_initializer='glorot_normal', padding='same')\n",
    "        self.conv2_2 = layers.Conv1D(self.f/4, self.k[1], kernel_initializer='glorot_normal', padding='same')\n",
    "        self.conv2_3 = layers.Conv1D(self.f/4, self.k[2], kernel_initializer='glorot_normal', padding='same')\n",
    "        self.conv2_4 = layers.Conv1D(self.f/4, self.k[3], kernel_initializer='glorot_normal', padding='same')\n",
    "        self.conv2_5 = layers.Conv1D(self.f/4, self.k[4], kernel_initializer='glorot_normal', padding='same')\n",
    "        self.batch2 = layers.BatchNormalization()\n",
    "        self.activation2 = layers.Activation(tf.nn.relu)\n",
    "        \n",
    "        self.outconv = layers.Conv1D(self.f, 1, kernel_initializer='glorot_normal', padding='same')\n",
    "        self.outbatch = layers.BatchNormalization()\n",
    "        self.outact = layers.Activation(tf.nn.relu)\n",
    "        \n",
    "    def call(self, inp):\n",
    "        \n",
    "        shortcut = self.downbatch(self.downsampling(inp))\n",
    "        \n",
    "        inp = self.activation1(self.batch1(self.conv1(inp)))\n",
    "        \n",
    "        inp = tf.concat([self.conv2_1(inp), self.conv2_2(inp), self.conv2_3(inp), self.conv2_4(inp), self.conv2_5(inp)], -1)\n",
    "        inp = self.activation2(self.batch2(inp))\n",
    "        \n",
    "        inp = self.outbatch(self.outconv(inp))\n",
    "        inp = self.outact(layers.add([shortcut, inp]))\n",
    "                \n",
    "        return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet1D(Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet1D, self).__init__()\n",
    "        self.n = [128, 128, 256, 256, 512] # number of nodes\n",
    "        self.k = [1, 3, 5, 10, 20] # kernal size\n",
    "        self.s = 2 # stride (= pooling size)\n",
    "                \n",
    "        self.conv_block1_1 = ConvBlock(self.n[0], self.k)\n",
    "        self.conv_block1_2 = ConvBlock(self.n[0], self.k)\n",
    "        self.conv_block1_3 = ConvBlock(self.n[0], self.k)\n",
    "        self.conv_block1_4 = ConvBlock(self.n[0], self.k)\n",
    "        self.gate1 = layers.Dense(self.n[0], activation=tf.nn.sigmoid)\n",
    "        self.pool1 = layers.Conv1D(self.n[1], self.s, self.s)\n",
    "\n",
    "        self.conv_block2_1 = ConvBlock(self.n[1], self.k)\n",
    "        self.conv_block2_2 = ConvBlock(self.n[1], self.k)\n",
    "        self.conv_block2_3 = ConvBlock(self.n[1], self.k)\n",
    "        self.conv_block2_4 = ConvBlock(self.n[1], self.k)\n",
    "        self.gate2 = layers.Dense(self.n[1], activation=tf.nn.sigmoid)\n",
    "        self.pool2 = layers.Conv1D(self.n[2], self.s, self.s)\n",
    "        \n",
    "        self.conv_block3_1 = ConvBlock(self.n[2], self.k)\n",
    "        self.conv_block3_2 = ConvBlock(self.n[2], self.k)\n",
    "        self.conv_block3_3 = ConvBlock(self.n[2], self.k)\n",
    "        self.conv_block3_4 = ConvBlock(self.n[2], self.k)\n",
    "        self.gate3 = layers.Dense(self.n[2], activation=tf.nn.sigmoid)\n",
    "        self.pool3 = layers.Conv1D(self.n[3], self.s, self.s)\n",
    "        \n",
    "        self.conv_block4_1 = ConvBlock(self.n[3], self.k)\n",
    "        self.conv_block4_2 = ConvBlock(self.n[3], self.k)\n",
    "        self.conv_block4_3 = ConvBlock(self.n[3], self.k)\n",
    "        self.conv_block4_4 = ConvBlock(self.n[3], self.k)\n",
    "        self.conv_block4_5 = ConvBlock(self.n[3], self.k)\n",
    "        self.gate4 = layers.Dense(self.n[3], activation=tf.nn.sigmoid)\n",
    "        self.pool4 = layers.Conv1D(self.n[4], self.s, self.s)\n",
    "        \n",
    "        self.conv_block5_1 = ConvBlock(self.n[4], self.k)\n",
    "        self.conv_block5_2 = ConvBlock(self.n[4], self.k)\n",
    "        self.conv_block5_3 = ConvBlock(self.n[4], self.k)\n",
    "        self.conv_block5_4 = ConvBlock(self.n[4], self.k)\n",
    "        self.conv_block5_5 = ConvBlock(self.n[4], self.k)\n",
    "        self.conv_block5_6 = ConvBlock(self.n[4], self.k)\n",
    "        self.gate5 = layers.Dense(self.n[4], activation=tf.nn.sigmoid)\n",
    "        \n",
    "#         self.output_conv = layers.Conv1D(1, 1, activation='sigmoid')\n",
    "        self.outgate = layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "        \n",
    "    def call(self, inp):\n",
    "        \n",
    "        conv1 = self.conv_block1_1(inp)\n",
    "        conv1 = self.conv_block1_2(conv1)\n",
    "        conv1 = self.conv_block1_3(conv1)\n",
    "        conv1 = self.conv_block1_4(conv1)\n",
    "        conv1 = self.gate1(conv1)\n",
    "        conv1 = self.pool1(conv1)\n",
    "        \n",
    "        conv2 = self.conv_block2_1(conv1)\n",
    "        conv2 = self.conv_block2_2(conv2)\n",
    "        conv2 = self.conv_block2_3(conv2)\n",
    "        conv2 = self.conv_block2_4(conv2)\n",
    "        conv2 = self.gate2(conv2)\n",
    "        conv2 = self.pool2(conv2)\n",
    "        \n",
    "        conv3 = self.conv_block3_1(conv2)\n",
    "        conv3 = self.conv_block3_2(conv3)\n",
    "        conv3 = self.conv_block3_3(conv3)\n",
    "        conv3 = self.conv_block3_4(conv3)\n",
    "        conv3 = self.gate3(conv3)\n",
    "        conv3 = self.pool3(conv3)\n",
    "        \n",
    "        conv4 = self.conv_block4_1(conv3)\n",
    "        conv4 = self.conv_block4_2(conv4)\n",
    "        conv4 = self.conv_block4_3(conv4)\n",
    "        conv4 = self.conv_block4_4(conv4)\n",
    "        conv4 = self.conv_block4_5(conv4)\n",
    "        conv4 = self.gate4(conv4)\n",
    "        conv4 = self.pool4(conv4)\n",
    "\n",
    "        conv5 = self.conv_block5_1(conv4)\n",
    "        conv5 = self.conv_block5_2(conv5)\n",
    "        conv5 = self.conv_block5_3(conv5)\n",
    "        conv5 = self.conv_block5_4(conv5)\n",
    "        conv5 = self.conv_block5_5(conv5)\n",
    "        conv5 = self.conv_block5_6(conv5)\n",
    "        conv5 = self.gate5(conv5)\n",
    "        \n",
    "        return self.outgate(conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=.5, patience=2, verbose=0, mode='min',\n",
    "    min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "save = tf.keras.callbacks.ModelCheckpoint(\n",
    "    BEST_PATH, monitor='val_loss', verbose=0,\n",
    "    save_best_only=True, save_weights_only=True, mode='min', save_freq='epoch')\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, epsilon=EPSILON)\n",
    "    model = ResNet1D()\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "    model.fit(train_dataset, epochs=TRAINING_EPOCHS, validation_data=val_dataset,\n",
    "                  verbose=1, callbacks=[callbacks, save, early_stop]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(BEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.019411545246839523"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf20",
   "language": "python",
   "name": "tf20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
